{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbTPpiVPl2cE5GpECajaRp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CharFox1/CompVisProj/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL7yYumqgmQQ"
      },
      "source": [
        "from torch import nn, tensor\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNYNEbHSiy2G",
        "outputId": "7c06adae-0bb5-4e51-f3bf-18d3eab168cf"
      },
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QTU6t3eT2M4"
      },
      "source": [
        "# simple conv network to test finding single characters\n",
        "# uses resnet-4 structure\n",
        "\n",
        "class convDemoNet(nn.Module):\n",
        "  def __init__(self, numClasses):\n",
        "    super(convDemoNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=2)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.output = nn.Linear(1922, numClasses)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 1, 32, 32)\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.flatten(x)\n",
        "    return self.output(x)\n"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "w4mYNjCXUW_I",
        "outputId": "540d758e-7da9-48d1-a489-dfd14f4ff491"
      },
      "source": [
        "# get conv demo data (https://www.kaggle.com/vaibhao/handwritten-characters)\n",
        "from google.colab.patches import cv2_imshow #allows us to show images\n",
        "\n",
        "# grab small files (created from larger dataset)\n",
        "# this is the location they should be in the github\n",
        "# if you are running in collab, you need to import the handwrittenChars folder as a zip\n",
        "# you can unzip it with \"!unzip handwrittenChars.zip\" in a separate cell\n",
        "with open(\"handwrittenChars/trainSmall.npy\", \"rb\") as f:\n",
        "    conv_train_data = np.load(f, allow_pickle=True)\n",
        "\n",
        "with open(\"handwrittenChars/valSmall.npy\", \"rb\") as f:\n",
        "    conv_val_data = np.load(f, allow_pickle=True)\n",
        "\n",
        "print(\"training data size:\", len(conv_train_data))\n",
        "print(\"validation data size:\", len(conv_val_data))\n",
        "\n",
        "print(\"training data shape:\", conv_train_data[1201][0].shape)\n",
        "cv2_imshow(conv_train_data[1201][0])\n",
        "print(\"data type of image =\", type(conv_train_data[1201][0]))\n",
        "print(\"training data label:\", conv_train_data[1201][1])\n",
        "print(\"each index in dataset has image (32x32) and char label\")"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data size: 78000\n",
            "validation data size: 13209\n",
            "training data shape: (32, 32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABVElEQVR4nNWRsUtCURTGf/WiEHk9FwepIRV6EDx4W6O4uDjkGI36B+gQEbQ1NJgQIjQ0OBUEDkXRUpDSH5CgU4O9hpwcnlJIEXEaLPXRda9vufec853vnvNd+LcIxSdVfLbtA9bqw8y0l2DW6ybM+ZlEGCB9NLrPqAizfrMOFE5+l2wRm0xDRET2omqFzU7Mol2Ay5ZC3BYRqdVktIVHIWotQbVXjixXVaOF7byIiA3ZM4Bw0Kugl5LvXU0fBJoOpZsi4z5cJSiHk9/BiuM4ifEZzFPMrVqn+zII45UA6w/t0fOrtyK5EGBsvNpkGvKYShlj48UunnO5IAAB9/jgXsbWBCA3TAS3+yofWufOjw+71x+UIzGVDbCQl/6dDmR/O6npwE6624zNa5+qZst1XfftMKAbT5ZaIQDsF7tmZVHztk4NDiMONFsYcao9olZP+Vt/Fl8w9HTyIRS5+gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=32x32 at 0x7FCEC5B77E10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "data type of image = <class 'numpy.ndarray'>\n",
            "training data label: #\n",
            "each index in dataset has image (32x32) and char label\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD8KefvjlQUq",
        "outputId": "426e666e-fe96-4515-e06a-16e3f2f99dd2"
      },
      "source": [
        "labels = []\n",
        "for i in conv_train_data:\n",
        "  label = i[1]\n",
        "  if label not in labels:\n",
        "    labels.append(label)\n",
        "\n",
        "print(\"there are\", len(labels), \"labels in the training dataset\")\n",
        "\n",
        "for i in conv_val_data:\n",
        "  label = i[1]\n",
        "  if label not in labels:\n",
        "    labels.append(label)\n",
        "\n",
        "print(\"there are\", len(labels), \"labels in the validation dataset\")\n",
        "\n",
        "labelDict = {}\n",
        "for i in range(len(labels)):\n",
        "  labelDict[i] = labels[i]\n",
        "\n",
        "print(labelDict)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 39 labels in the training dataset\n",
            "there are 39 labels in the validation dataset\n",
            "{0: '#', 1: '$', 2: '&', 3: '0', 4: '1', 5: '2', 6: '3', 7: '4', 8: '5', 9: '6', 10: '7', 11: '8', 12: '9', 13: '@', 14: 'A', 15: 'B', 16: 'C', 17: 'D', 18: 'E', 19: 'F', 20: 'G', 21: 'H', 22: 'I', 23: 'J', 24: 'K', 25: 'L', 26: 'M', 27: 'N', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNPEtqWcwx7U"
      },
      "source": [
        "# dataset class\n",
        "class handwrittenCharsDataset(Dataset):\n",
        "    def __init__(self, X):\n",
        "      self.images = []\n",
        "      self.labels = []\n",
        "      for i in X:\n",
        "        self.images.append(i[0])\n",
        "        self.labels.append(i[1])\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      image = self.images[index]\n",
        "      label = self.labels[index]\n",
        "      image = self.transform(image)\n",
        "      sample = [image, label]\n",
        "      return sample\n",
        "    \n",
        "    transform = T.Compose([\n",
        "      T.ToPILImage(),\n",
        "      T.ToTensor()                     \n",
        "    ])"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GxpW2tg1X-9"
      },
      "source": [
        "batch_size = 10\n",
        "dataset = handwrittenCharsDataset(X=conv_train_data)\n",
        "train_dl = DataLoader(dataset, batch_size, shuffle=True)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6jwvAQ8stBB"
      },
      "source": [
        "for step, batch in enumerate(train_dl):\n",
        "  images, labels = batch\n",
        "  print(images)\n",
        "  print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It_9ZFvtaHMU",
        "outputId": "67ebf061-5207-424d-e1f7-abede9b6c730"
      },
      "source": [
        "# init model with 39 classes on output layer\n",
        "# put model in gpu if available\n",
        "convModel = convDemoNet(39).to(device)\n",
        "print(convModel)\n",
        "\n",
        "testItem, testLabel = next(iter(train_dl))\n",
        "\n",
        "testItem = testItem[0]\n",
        "testLabel = testLabel[0]\n",
        "\n",
        "output = convModel(testItem)\n",
        "pred_prob = nn.Softmax(dim=1)(output)\n",
        "y_pred = labelDict[pred_prob.argmax(1).item()]\n",
        "print(\"predicted\", y_pred, \"for\", testLabel)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convDemoNet(\n",
            "  (conv1): Conv2d(1, 2, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (output): Linear(in_features=1922, out_features=39, bias=True)\n",
            ")\n",
            "predicted 8 for @\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}